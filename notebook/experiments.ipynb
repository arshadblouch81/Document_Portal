{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a1730b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb632f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e328c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89850212",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c583a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object GoogleGenerativeAIEmbeddings.aembed_query at 0x000002099DED39A0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.aembed_query(\"This is my fist query to embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158235fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1022f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdf_dir=os.path.join(os.getcwd(), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df74e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadError(\"Invalid Elementary Object starting with b'P' @18807504: b'7 0 obj<</Universal PDF(The process that creates this PDF constitutes a trade se'\")\n"
     ]
    }
   ],
   "source": [
    "# List all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
    "\n",
    "# Load all PDFs\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    file_path = os.path.join(pdf_dir, pdf_file)\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents.extend(loader.load()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5a133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c536afd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\sample_data.pdf'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "528d1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadError(\"Invalid Elementary Object starting with b'P' @18807504: b'7 0 obj<</Universal PDF(The process that creates this PDF constitutes a trade se'\")\n"
     ]
    }
   ],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85f31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 500,\n",
    "    chunk_overlap = 150,\n",
    "    length_function = len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe4b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs= text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac95000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18cf71cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.3',\n",
       " 'creator': 'Elsevier',\n",
       " 'creationdate': '2015-06-13T13:55:15+05:30',\n",
       " 'author': 'Cheikh Kacfah Emani',\n",
       " 'crossmarkdomains[1]': 'sciencedirect.com',\n",
       " 'crossmarkdomains[2]': 'elsevier.com',\n",
       " 'crossmarkdomainexclusive': 'true',\n",
       " 'crossmarkmajorversiondate': '2010-04-23',\n",
       " 'elsevierwebpdfspecifications': '6.4',\n",
       " 'moddate': '2015-06-13T13:55:27+05:30',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009/Debian) kpathsea version 5.0.0',\n",
       " 'subject': 'Computer Science Review, Corrected proof. doi:10.1016/j.cosrev.2015.05.002',\n",
       " 'title': 'Understandable Big Data: A survey',\n",
       " 'trapped': '/False',\n",
       " 'doi': '10.1016/j.cosrev.2015.05.002',\n",
       " 'robots': 'noindex',\n",
       " 'source': 'd:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\2. Understanding Big ata.pdf',\n",
       " 'total_pages': 12,\n",
       " 'page': 1,\n",
       " 'page_label': '2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3050d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a0b0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'size is beyond the ability of typical database software tools\\nto capture, store, manage, and analyze”. Likewise, Davis and\\nPatterson [1, page 4] say “Big data is data too big to be handled\\nand analyzed by traditional database protocols such as SQL”;\\nand the same opinion is shared by [11,3,4], etc. Both groups of\\nauthors previously mentioned go beyond the only size aspects\\nof data when defining Big Data! Edd Dumbill in [12, page 3]\\nexplicitly conveys the multi-dimensionality of Big Data when'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[105].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.embed_documents((docs[105].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423bcbc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAISS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m.from_documents(docs, embedding_model)\n",
      "\u001b[31mNameError\u001b[39m: name 'FAISS' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f082f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_retreived = vectorstore.similarity_search('what ajk policy lakes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4df49052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Kashmir Digital Policy 2024 -2030 outlines a comprehensive framework aimed at enhancing access, \n",
      "connectivity, and digital infrastructure while also promoting digital governance, legislation, human resource \n",
      "development, and private sector innovation. \n",
      "A critical analysis of this policy reveals several strengths and potential weaknesses: \n",
      "Strengths: \n",
      "1. Holistic Approach : The policy covers multiple core areas, indicating a well -rounded strategy that' metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-09-13T05:28:42+05:00', 'author': 'arshad abbas', 'moddate': '2024-09-13T05:28:42+05:00', 'source': 'd:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\The Kashmir Digital Policy 2024.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "page_content='implemented in educational institutions to develop skilled AI practitioners and data scientists. \n",
      "In conclusion, the Kashmir Digital Policy 2024 -2030 presents a forward -thinking framework that has the \n",
      "potential to significantly enhance the region's digital landscape. However, careful attention must be paid to \n",
      "implementation, inclusivity, and sustainability to ensure that the policy achieves its intended outcomes.' metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-09-13T05:28:42+05:00', 'author': 'arshad abbas', 'moddate': '2024-09-13T05:28:42+05:00', 'source': 'd:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\The Kashmir Digital Policy 2024.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "page_content='challenges. \n",
      "5. Encouragement of Entrepreneurship : Promoting innovation and private sector development can \n",
      "stimulate the local economy, create jobs, and encourage a culture of entrepreneurship, which is \n",
      "essential for long-term sustainability. \n",
      "Weaknesses: \n",
      "1. Implementation Challenges: While the policy outlines significant guidelines, the success of such a \n",
      "comprehensive plan often hinges on effective implementation. Without a clear roadmap and adequate' metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-09-13T05:28:42+05:00', 'author': 'arshad abbas', 'moddate': '2024-09-13T05:28:42+05:00', 'source': 'd:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\The Kashmir Digital Policy 2024.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "page_content='POLICY\n",
      "ping from every possible state to the best move in that state. Then we can just look up the best\n",
      "move rather than recompute it anew. How big will the KBNK lookup table be? It turns out\n",
      "there are 462 ways that two kings can be placed on the board without being adjacent. After\n",
      "the kings are placed, there are 62 empty squares for the bishop, 61 for the knight, and two\n",
      "possible players to move next, so there are just 462 ×62 ×61 ×2=3 ,494,568 possible' metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'd:\\\\LLMOPS Industry Projects\\\\document_portal\\\\notebook\\\\data\\\\sample_data.pdf', 'total_pages': 1151, 'page': 194, 'page_label': '176'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs_retreived:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bb712d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver.invoke('search agents provides several opportunities for learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "266b3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Check the context and answer the question if you dont find any answer then return  o answer found\n",
    "\n",
    "context: {context}\n",
    "\n",
    "question {question}\n",
    "\n",
    "Answer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f38c3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate ( template=prompt_template,\n",
    "                         input_variables= ['context','question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e3b7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0aa8e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a099eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8565f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2878be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5fcbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retreiver | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22bb04c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out what the Metropolis algorithm is based on the given context. Let me read through the context carefully.\\n\\nFirst, I see that the context mentions \"MCMC algorithms\" which stand for Markov Chain Monte Carlo. It talks about generating samples by making random changes to the preceding sample, which is a key part of MCMC methods.\\n\\nThen, there\\'s a section about the Metropolis–Hastings algorithm. It says that this algorithm operates in two stages. The first stage is sampling a new state x\\' from a proposal distribution q(x\\'|x) given the current state x. The second stage is about accepting or rejecting this new state with a certain probability α(x\\'|x). The acceptance probability is calculated as the minimum of 1 and the ratio of π(x\\')q(x|x\\') to π(x)q(x\\'|x). If the proposal is rejected, the state stays at x.\\n\\nSo, putting this together, the Metropolis algorithm, which is a specific case of Metropolis–Hastings, uses a symmetric proposal distribution where q(x\\'|x) = q(x|x\\'), simplifying the acceptance probability to min(1, π(x\\')/π(x)). This means it only depends on the ratio of the target distributions at the proposed and current states.\\n\\nI should make sure I\\'m not confusing it with Gibbs sampling, which is another MCMC method. Gibbs sampling updates one variable at a time while conditioning on the others, which is different from the Metropolis approach.\\n\\nI think I have enough information here to describe the Metropolis algorithm accurately.\\n</think>\\n\\nThe Metropolis algorithm is a Markov Chain Monte Carlo (MCMC) method used for generating samples from a target distribution, π(x). It operates in two main stages:\\n\\n1. **Proposal Stage**: A new state x\\' is proposed using a proposal distribution q(x\\'|x), given the current state x.\\n\\n2. **Acceptance Stage**: The proposed state x\\' is accepted with probability α(x\\'|x), which is the minimum of 1 and the ratio π(x\\')/π(x). If the proposal is accepted, the state moves to x\\'; otherwise, it remains at x.\\n\\nThis method is a specific case of the Metropolis–Hastings algorithm, distinguished by its use of a symmetric proposal distribution, simplifying the acceptance probability calculation. It is widely used for Bayesian inference and is particularly effective for sampling from complex distributions.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('what is Metropolis algorithm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
